# SecureBank Fraud Detection System

A comprehensive fraud detection system built with Flask, scikit-learn, and Docker for real-time transaction analysis and model training.

## ğŸš€ Quick Start

### Prerequisites
- Docker
- Python 3.9+ (for local development)
- bash (for running test scripts)

### Running the System

1. **Build and Start the Server**
   ```bash
   cd securebank/executables
   chmod +x *.sh
   ./run_server.sh
   ```

2. **Test the Prediction Endpoint**
   ```bash
   ./predict.sh
   ```

3. **Test Dataset Creation**
   ```bash
   ./create_dataset.sh
   ```

4. **Test Model Training**
   ```bash
   ./train_model.sh
   ```

## ğŸ“ Project Structure

```
securebank/
â”œâ”€â”€ Dockerfile                      # Docker configuration
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ app.py                         # Main Flask application
â”œâ”€â”€ test.json                      # Sample test data
â”œâ”€â”€ engineer_from_raw.py           # create engineered dataset from sources and test with xgboost
â”œâ”€â”€ sampled_engineered_dataset.py  # create smaller dataset from engineered dataset
â”œâ”€â”€ train_lightgbm.py              # dev script for training model
â”œâ”€â”€ train_with_adasyn.py           # dev script for training model
â”œâ”€â”€ train_model_docker.py          # dev script for training model    
â”œâ”€â”€ modules/                       # Core modules
â”‚   â”œâ”€â”€ data/                      # Data processing
â”‚   â”‚   â””â”€â”€ raw_data_handler.py    # Data handling utilities
â”‚   â””â”€â”€ utils/                     # Utility modules
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ advanced_logging.py
â”‚       â”œâ”€â”€ data_drift_detector.py # detect drift on new data.
â”‚       â”œâ”€â”€ logging_utils.py       # Logging system
â”‚       â””â”€â”€ model_utils.py         # Model management
â”œâ”€â”€ logs/                          # System logs (JSON files)
â”œâ”€â”€ storage/
â”‚   â””â”€â”€ datasets/                  # Generated training datasets
â”‚   â””â”€â”€ models/                    # Trained models
â”œâ”€â”€ data_sources/                  # Raw data files
â””â”€â”€ executables/                   # Test scripts
    â”œâ”€â”€ run_server.sh             # Build and run Docker container
    â”œâ”€â”€ predict.sh                # Test prediction endpoint
    â”œâ”€â”€ create_dataset.sh         # Test dataset creation
    â””â”€â”€ train_model.sh            # Test model training
```

## ğŸ”Œ API Endpoints

### POST `/predict`
Predict fraud for a single transaction.

**Request Body:**
```json
{
    "trans_date_trans_time": "2021-10-07 12:01:55",
    "cc_num": "4059294504000000", 
    "unix_time": 1633608115,
    "merchant": "Walmart",
    "category": "grocery_pos",
    "amt": 45.23,
    "merch_lat": 40.7589,
    "merch_long": -73.9851
}
```

**Response:**
```json
{
    "predict": "legitimate",
    "probability": 0.15
}
```

### POST `/create_dataset`
Generate high-quality training dataset from raw data sources.

**Response:**
```json
{
    "status": "success",
    "dataset_path": "storage/datasets/dataset_train_20231201_143022.csv",
    "records": 50000,
    "fraud_rate": 0.05
}
```

### POST `/train_model`
Train a new fraud detection model on the latest dataset.

**Response:**
```json
{
    "status": "success",
    "model_id": "fraud_model_20231201_143500_p0.752_r0.689",
    "performance": {
        "precision": 0.752,
        "recall": 0.689,
        "f1_score": 0.719
    }
}
```

### GET `/health`
Health check endpoint for monitoring.

**Response:**
```json
{
    "status": "healthy",
    "timestamp": "2023-12-01T14:35:00",
    "model_loaded": true
}
```

## ğŸ“Š Model Requirements

- **Performance**: â‰¥70% precision and â‰¥70% recall on production datasets
- **Features**: Uses both transaction and customer data
- **Training Time**: Completes in under 15 minutes without GPU
- **Architecture**: Logistic regression with preprocessing pipeline

## ğŸ“ Logging and Monitoring

All requests and operations are logged as JSON files in the `logs/` directory with timestamps:

- **Prediction requests**: Request data, predictions, response times
- **Training activities**: Model performance, training metrics
- **Dataset generation**: Dataset statistics, processing time
- **System errors**: Error details and context

Example log file: `logs/log_20231201_143022_123.json`

## ğŸ§ª Testing

The system includes comprehensive bash scripts for testing all functionality:

```bash
# Start the system
./executables/run_server.sh

# Test prediction (requires trained model)
./executables/predict.sh [json_file] [host] [port]

# Generate training dataset
./executables/create_dataset.sh [host] [port] 

# Train new model
./executables/train_model.sh [host] [port]
```

## ğŸ› Development Status

**Phase 1: âœ… Complete** - Project structure and basic Flask app
- âœ… Organized project structure
- âœ… Basic Flask application with `/predict` endpoint
- âœ… Logging and model management utilities
- âœ… Docker configuration
- âœ… Test scripts

**Phase 2: ğŸš§ In Progress** - Enhanced Flask endpoints
**Phase 3: ğŸ“‹ Planned** - Complete logging system
**Phase 4: ğŸ“‹ Planned** - Dataset generation service  
**Phase 5: ğŸ“‹ Planned** - Model training service
**Phase 6: ğŸ“‹ Planned** - Final integration and testing

## ğŸ”§ Local Development

For local development without Docker:

```bash
# Install dependencies
pip install -r requirements.txt

# Run the application
python app.py

# Test endpoints
curl -X POST http://localhost:5000/predict \
     -H "Content-Type: application/json" \
     -d @test.json
```

## ğŸ“„ License

This project is part of the SecureBank fraud detection system assignment.